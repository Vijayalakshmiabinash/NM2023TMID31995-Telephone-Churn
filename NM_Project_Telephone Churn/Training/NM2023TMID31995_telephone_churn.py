# -*- coding: utf-8 -*-
"""Telephone_churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UO2ryH_uszryAewspDF8n-arSGF5sXei
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pickle
from  google.colab import files
import io
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import sklearn
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
import imblearn
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

data=files.upload()

data=pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
df=data
data

data = data.iloc[:,1:]
data.info()

data.TotalCharges=pd.to_numeric(data.TotalCharges,errors='coerce')
data.isnull().any()

data.TotalCharges.fillna(data.TotalCharges.mean(), inplace=True)
data.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data["gender"]=le.fit_transform(data["gender"])
data["Partner"]=le.fit_transform(data["Partner"])
data["Dependents"]=le.fit_transform(data["Dependents"])
data["PhoneService"]=le.fit_transform(data["PhoneService"])
data["MultipleLines"]=le.fit_transform(data["MultipleLines"])
data["InternetService"]=le.fit_transform(data["InternetService"])
data["OnlineSecurity"]=le.fit_transform(data["OnlineSecurity"])
data["OnlineBackup"]=le.fit_transform(data["OnlineBackup"])
data["DeviceProtection"]=le.fit_transform(data["DeviceProtection"])
data["TechSupport"]=le.fit_transform(data["TechSupport"])
data["StreamingTV"]=le.fit_transform(data["StreamingTV"])
data["StreamingMovies"]=le.fit_transform(data["StreamingMovies"])
data["Contract"]=le.fit_transform(data["Contract"])
data["PaperlessBilling"]=le.fit_transform(data["PaperlessBilling"])
data["PaymentMethod"]=le.fit_transform(data["PaymentMethod"])
data["Churn"]=le.fit_transform(data["Churn"])

data.head()

x=data.iloc[:,0:19].values
y=data.iloc[:,19:20].values

x

y

from sklearn.preprocessing import OneHotEncoder
one=OneHotEncoder()
a=one.fit_transform(x[:,6:7]).toarray()
b=one.fit_transform(x[:,7:8]).toarray()
c=one.fit_transform(x[:,8:9]).toarray()
d=one.fit_transform(x[:,9:10]).toarray()
e=one.fit_transform(x[:,10:11]).toarray()
f=one.fit_transform(x[:,11:12]).toarray()
g=one.fit_transform(x[:,12:13]).toarray()
h=one.fit_transform(x[:,13:14]).toarray()
i=one.fit_transform(x[:,14:15]).toarray()
j=one.fit_transform(x[:,16:17]).toarray()
x=np.delete(x,[6,7,8,9,10,11,12,13,14,16],axis=1)
x=np.concatenate((a,b,c,d,e,f,g,h,i,j,x),axis=1)

x

y

from imblearn.over_sampling import SMOTE
sm = SMOTE()
x_resampled, y_resampled = sm.fit_resample(x, y)

x_resampled

y_resampled

x.shape,x_resampled.shape

y.shape,y_resampled.shape

data.describe()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.distplot(data["tenure"])
plt.subplot(1,2,2)
sns.distplot(data["MonthlyCharges"])

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.countplot(data["gender"])
plt.subplot(1,2,2)
sns.countplot(data["Dependents"])

sns.barplot(x="Churn",y="MonthlyCharges",data=data)

sns.heatmap(df.corr(),annot=True)

sns.pairplot(data=df,markers=["^","v"],palette="inferno")

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x_resampled,y_resampled,test_size=0.2,random_state=0)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.fit_transform(x_test)
x_train.shape

def logreg(x_train,x_test,y_train,y_test):
  lr=LogisticRegression(random_state=0)
  lr.fit(x_train,y_train)
  ylt=lr.predict(x_train)
  print("Accuracy Score :",accuracy_score(ylt,y_train))
  yPred_lr=lr.predict(x_test)
  print("Accuracy Test :",accuracy_score(yPred_lr,y_test))
  print("Logistic Regression")
  print("Confusion Matrix")
  print(confusion_matrix(y_test, yPred_lr))
  print("Classification Reprot")
  print(classification_report(y_test, yPred_lr))

logreg(x_train,x_test,y_train,y_test)

def dTree(x_train,x_test,y_train,y_test):
  dtc=DecisionTreeClassifier(criterion="entropy",random_state=0)
  dtc.fit(x_train,y_train)
  y_dt_tr=dtc.predict(x_train)
  print("Accuracy Score :",accuracy_score(y_dt_tr,y_train))
  yPred_dt=dtc.predict(x_test)
  print("Accuracy Test :",accuracy_score(yPred_dt,y_test))
  print("Decsion Tree")
  print("Confusion Matrix")
  print(confusion_matrix(y_test, yPred_dt))
  print("Classification Reprot")
  print(classification_report(y_test, yPred_dt))

dTree(x_train,x_test,y_train,y_test)

def RandomForest(x_train,x_test,y_train,y_test):
  rf=RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
  rf.fit(x_train,y_train)
  y_rf_tr=rf.predict(x_train)
  print("Accuracy Score :",accuracy_score(y_rf_tr,y_train))
  yPred_rf=rf.predict(x_test)
  print("Accuracy Test :",accuracy_score(yPred_rf,y_test))
  print("Random Forest")
  print("Confusion Matrix")
  print(confusion_matrix(y_test, yPred_rf))
  print("Classification Reprot")
  print(classification_report(y_test, yPred_rf))

RandomForest(x_train,x_test,y_train,y_test)

def KNN(x_train,x_test,y_train,y_test):
  knn=KNeighborsClassifier()
  knn.fit(x_train,y_train)
  y_knn_tr=knn.predict(x_train)
  print("Accuracy Score :",accuracy_score(y_knn_tr,y_train))
  yPred_knn=knn.predict(x_test)
  print("Accuracy Test :",accuracy_score(yPred_knn,y_test))
  print("KNN")
  print("Confusion Matrix")
  print(confusion_matrix(y_test, yPred_knn))
  print("Classification Reprot")
  print(classification_report(y_test, yPred_knn))

KNN(x_train,x_test,y_train,y_test)

def SVM(x_train,x_test,y_train,y_test):
  svm=KNeighborsClassifier()
  svm.fit(x_train,y_train)
  y_svm_tr=svm.predict(x_train)
  print("Accuracy Score :",accuracy_score(y_svm_tr,y_train))
  yPred_svm=svm.predict(x_test)
  print("Accuracy Test :",accuracy_score(yPred_svm,y_test))
  print("SVM")
  print("Confusion Matrix")
  print(confusion_matrix(y_test, yPred_svm))
  print("Classification Reprot")
  print(classification_report(y_test, yPred_svm))

SVM(x_train,x_test,y_train,y_test)

import keras
from keras.models import Sequential
from keras.layers import Dense
classifier=Sequential()
classifier.add(Dense(units=30, activation="relu",input_dim=40))
classifier.add(Dense(units=30, activation="relu"))
classifier.add(Dense(units=1, activation="sigmoid"))
classifier.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

model_histroty=classifier.fit(x_train,y_train, batch_size=10, validation_split=0.33,epochs=200)

ann_pred=classifier.predict(x_test)
ann_pred=(ann_pred>0.5)
ann_pred

print("Accuracy Test :",accuracy_score(ann_pred,y_test))
print("ANN model")
print("Confusion Matrix")
print(confusion_matrix(y_test, ann_pred))
print("Classification Reprot")
print(classification_report(y_test, ann_pred))

lr=LogisticRegression(random_state=0)
lr.fit(x_train,y_train)
print("Predicting on random input")
lr_pred_own=lr.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", lr_pred_own)

dtc=DecisionTreeClassifier(criterion="entropy",random_state=0)
dtc.fit(x_train,y_train)
print("Predicting on random input")
dtc_pred_own=dtc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", dtc_pred_own)

rf=RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
rf.fit(x_train,y_train)
print("Predicting on random input")
rf_pred_own=rf.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", rf_pred_own)

print("Predicting on random input")
ann_pred_own=classifier.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
ann_pred_own=(ann_pred_own>0.5)
print("output is :", ann_pred_own)

svc=SVC(kernel="linear")
svc.fit(x_train,y_train)
print("Predicting on random input")
svm_pred_own=svc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", svm_pred_own)

knn=KNeighborsClassifier()
knn.fit(x_train,y_train)
print("Predicting on random input")
knn_pred_own=knn.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", knn_pred_own)

print("Predicting on random input")
ann_pred_own=classifier.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print(ann_pred_own)
ann_pred_own=(ann_pred_own>0.5)
print("output is :", ann_pred_own)

def comp_mod(x_train,x_test,y_train,y_test):
  logreg(x_train,x_test,y_train,y_test)
  print("-"*100)
  dTree(x_train,x_test,y_train,y_test)
  print("-"*100)
  RandomForest(x_train,x_test,y_train,y_test)
  print("-"*100)
  SVM(x_train,x_test,y_train,y_test)
  print("-"*100)
  KNN(x_train,x_test,y_train,y_test)
  print("-"*100)

comp_mod(x_train,x_test,y_train,y_test)

model = RandomForestClassifier()
model.fit(x_train, y_train)
y_rf=model.predict(x_train)
print(accuracy_score(y_rf,y_train))
y_pred_rcv=model.predict(x_test)
print(accuracy_score(y_pred_rcv,y_test))
print("**Random Forest after Hyperparameter tuning**")
print("Confusion Matrix")
print(confusion_matrix(y_test, y_pred_rcv))
print("Classification Reprot")
print(classification_report(y_test, y_pred_rcv))
print("Predicting on random input")
rfcv_pred_own=model.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is :", rfcv_pred_own)

classifier.save("telecom_churn.h5")